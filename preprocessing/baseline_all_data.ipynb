{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Feature        Type  \\\n",
      "0                      adres_aantal_brp_adres     Integer   \n",
      "1           adres_aantal_verschillende_wijken     Integer   \n",
      "2                   adres_aantal_verzendadres     Integer   \n",
      "3            adres_aantal_woonadres_handmatig     Integer   \n",
      "4                        adres_dagen_op_adres     Integer   \n",
      "..                                        ...         ...   \n",
      "313  typering_transport__logistiek___tuinbouw      Binary   \n",
      "314       typering_zorg__schoonmaak___welzijn      Binary   \n",
      "315                                        Ja  Continuous   \n",
      "316                                       Nee  Continuous   \n",
      "317                                   checked      Binary   \n",
      "\n",
      "                                           Details  \n",
      "0                                   Range: 1 to 12  \n",
      "1                                    Range: 1 to 7  \n",
      "2                                    Range: 0 to 3  \n",
      "3                                    Range: 0 to 3  \n",
      "4                                Range: 0 to 24331  \n",
      "..                                             ...  \n",
      "313                                 Values: [0, 1]  \n",
      "314                                 Values: [0, 1]  \n",
      "315  Range: 0.232850968145946 to 0.840936767028055  \n",
      "316  Range: 0.159063232971945 to 0.767149031854054  \n",
      "317                          Values: [False, True]  \n",
      "\n",
      "[318 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def scale_features(df: pd.DataFrame, feature_names: list) -> pd.DataFrame:\n",
    "    \"\"\"Scale specified integer features using MinMaxScaler.\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df[feature_names] = scaler.fit_transform(df[feature_names])\n",
    "    return df\n",
    "\n",
    "def classify_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Classify features into Binary, Integer, Continuous, or Unknown.\"\"\"\n",
    "    summary = []\n",
    "    for col in df.columns:\n",
    "        col_data = df[col].dropna()\n",
    "        unique_vals = set(col_data.unique())\n",
    "        is_binary = unique_vals.issubset({0, 1})\n",
    "        is_integer = np.all(np.equal(np.mod(col_data, 1), 0))\n",
    "        \n",
    "        if is_binary:\n",
    "            feature_type = \"Binary\"\n",
    "            details = f\"Values: {sorted(unique_vals)}\"\n",
    "        elif is_integer:\n",
    "            feature_type = \"Integer\"\n",
    "            details = f\"Range: {col_data.min()} to {col_data.max()}\"\n",
    "        elif not is_integer and col_data.dtype.kind in 'fi':  # float or integer\n",
    "            feature_type = \"Continuous\"\n",
    "            details = f\"Range: {col_data.min()} to {col_data.max()}\"\n",
    "        else:\n",
    "            feature_type = \"Unknown\"\n",
    "            details = f\"Values: {sorted(unique_vals)}\"\n",
    "        \n",
    "        summary.append({\n",
    "            'Feature': col,\n",
    "            'Type': feature_type,\n",
    "            'Details': details\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "data = pd.read_csv('../data/all_data.csv')\n",
    "\n",
    "# Classify feature types\n",
    "feature_summary = classify_features(data)\n",
    "print(feature_summary)\n",
    "\n",
    "# Find integer features to scale\n",
    "integer_features = feature_summary[feature_summary['Type'] == 'Integer']['Feature'].tolist()\n",
    "integer_features = [feat for feat in integer_features if feat != 'persoon_leeftijd_bij_onderzoek']\n",
    "\n",
    "# Scale integer features\n",
    "data = scale_features(data, integer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv(f\"../data/all_data_scaled_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and target\n",
    "y = data[['Ja', 'checked']]\n",
    "X = data.drop(['Ja', 'Nee', 'checked'], axis=1).astype(np.float32)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 92.90%\n"
     ]
    }
   ],
   "source": [
    "# Define and train the logistic regression model\n",
    "# Define the regularization strength (alpha)\n",
    "# This can be tuned using cross-validation\n",
    "\n",
    "ridge_alpha = 1.0  # Example value; you may want to optimize this\n",
    "\n",
    "# Create a Ridge regressor with the specified alpha\n",
    "#regressor = Ridge(\n",
    "#    alpha=ridge_alpha,\n",
    "#    fit_intercept=True,\n",
    "#    copy_X=True,\n",
    "#    random_state=42\n",
    "#)\n",
    "\n",
    "regressor = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([('regression', regressor)])\n",
    "\n",
    "pipeline.fit(\n",
    "    X_train, y_train['Ja']\n",
    ")\n",
    "\n",
    "threshold = (0.697021996059818 + 0.697013377682873) / 2.0  #approx. boundary value in dataset\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test['checked'], y_pred > threshold)\n",
    "print(f\"Model accuracy: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GradientBoostingRegressor' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get the coefficients from the model\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m coefficients \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Get feature names from X_train\u001b[39;00m\n\u001b[0;32m      9\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GradientBoostingRegressor' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "linear_model = pipeline.named_steps['regression']\n",
    "\n",
    "# Get the coefficients from the model\n",
    "coefficients = linear_model.coef_\n",
    "\n",
    "# Get feature names from X_train\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame mapping feature names to their coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Calculate absolute coefficients for sorting\n",
    "coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "\n",
    "# Sort the DataFrame by absolute coefficient values in descending order\n",
    "coef_df_sorted = coef_df.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Select the top 30 features\n",
    "top_30_coef = coef_df_sorted.head(30)\n",
    "\n",
    "print(top_30_coef)\n",
    "\n",
    "# Optional: Sort the top 30 for better visualization (e.g., ascending order)\n",
    "#top_30_coef = top_30_coef.sort_values(by='Coefficient')\n",
    "\n",
    "# print coefficient for 'persoonlijke_eigenschappen_taaleis_voldaan' from coef_df\n",
    "print(coef_df[coef_df['Feature'] == 'persoonlijke_eigenschappen_taaleis_voldaan'])\n",
    "print(coef_df[coef_df['Feature'] == 'persoon_leeftijd_bij_onderzoek'])\n",
    "\n",
    "# Set the plot style for better aesthetics\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "sns.barplot(\n",
    "    x='Coefficient',\n",
    "    y='Feature',\n",
    "    data=top_30_coef,\n",
    "    palette='viridis'\n",
    ")\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Top 30 Feature Coefficients in Ridge Regression Model', fontsize=16)\n",
    "plt.xlabel('Coefficient Value', fontsize=14)\n",
    "plt.ylabel('Feature', fontsize=14)\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from onnx import helper\n",
    "import onnxruntime as rt\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = convert_sklearn(\n",
    "    pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "    target_opset=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add note to onnx graph such that it saves both the predicted risk value\n",
    "# and the 'checked' value based on if the risk value is higher than the\n",
    "# provided threshold.\n",
    "\n",
    "graph = onnx_model.graph\n",
    "threshold_node = helper.make_node(\n",
    "    \"Constant\",\n",
    "    inputs=[],\n",
    "    outputs=[\"threshold\"],\n",
    "    value=helper.make_tensor(\"value\", onnx.TensorProto.FLOAT, [], [threshold])\n",
    ")\n",
    "graph.node.append(threshold_node)\n",
    "\n",
    "greater_node = helper.make_node(\n",
    "    \"Greater\",\n",
    "    inputs=[graph.output[0].name, \"threshold\"],\n",
    "    outputs=[\"boolean_output\"]\n",
    ")\n",
    "graph.node.append(greater_node)\n",
    "\n",
    "boolean_output = helper.make_tensor_value_info(\"boolean_output\", onnx.TensorProto.BOOL, [None])\n",
    "graph.output.extend([boolean_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the ONNX model:  0.9289846153846154\n"
     ]
    }
   ],
   "source": [
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "# y_pred_onnx[0] = risk values\n",
    "# y_pred_onnx[1] = boolean value indicating if high risk or not\n",
    "accuracy_onnx_model = accuracy_score(y_test['checked'], y_pred_onnx[1])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(onnx_model, \"../model/gboost_regression_model_baseline_all_data.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Testing-33-nTsXcFu8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
