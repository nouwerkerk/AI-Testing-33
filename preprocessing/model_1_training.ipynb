{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Configuration and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define bins and labels for age categorization\n",
    "AGE_BINS = [17, 25, 45, 67]\n",
    "AGE_LABELS = ['18-25', '25-45', '45-67']\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(features_path: str) -> list:\n",
    "    \"\"\"Load features to exclude based on the inclusion criteria.\"\"\"\n",
    "    features_df = pd.read_csv(features_path, delimiter=';')\n",
    "    excluded = features_df[features_df['Include'] == 0]['Feature (nl)'].tolist()\n",
    "    print(f\"Number of features to exclude: {len(excluded)}\")\n",
    "    return excluded\n",
    "\n",
    "def classify_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Classify features into Binary, Integer, Continuous, or Unknown.\"\"\"\n",
    "    summary = []\n",
    "    for col in df.columns:\n",
    "        col_data = df[col].dropna()\n",
    "        unique_vals = set(col_data.unique())\n",
    "        is_binary = unique_vals.issubset({0, 1})\n",
    "        is_integer = np.all(np.equal(np.mod(col_data, 1), 0))\n",
    "        \n",
    "        if is_binary:\n",
    "            feature_type = \"Binary\"\n",
    "            details = f\"Values: {sorted(unique_vals)}\"\n",
    "        elif is_integer:\n",
    "            feature_type = \"Integer\"\n",
    "            details = f\"Range: {col_data.min()} to {col_data.max()}\"\n",
    "        elif not is_integer and col_data.dtype.kind in 'fi':  # float or integer\n",
    "            feature_type = \"Continuous\"\n",
    "            details = f\"Range: {col_data.min()} to {col_data.max()}\"\n",
    "        else:\n",
    "            feature_type = \"Unknown\"\n",
    "            details = f\"Values: {sorted(unique_vals)}\"\n",
    "        \n",
    "        summary.append({\n",
    "            'Feature': col,\n",
    "            'Type': feature_type,\n",
    "            'Details': details\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "def scale_features(df: pd.DataFrame, feature_names: list) -> pd.DataFrame:\n",
    "    \"\"\"Scale specified integer features using MinMaxScaler.\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df[feature_names] = scaler.fit_transform(df[feature_names])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features to exclude\n",
    "features_to_exclude = load_features(\"../data/features_to_include.csv\")\n",
    "\n",
    "# Load all data\n",
    "data = pd.read_csv(\"../data/all_data.csv\")\n",
    "print(f\"Number of samples: {data.shape[0]}\")\n",
    "print(f\"Number of features before exclusion: {data.shape[1]}\")\n",
    "\n",
    "# Drop excluded features\n",
    "data_copy = data.drop(columns=features_to_exclude)\n",
    "print(f\"Number of features after exclusion: {data_copy.shape[1]}\")\n",
    "\n",
    "# Classify feature types\n",
    "feature_summary = classify_features(data_copy)\n",
    "\n",
    "# Find integer features to scale\n",
    "integer_features = feature_summary[feature_summary['Type'] == 'Integer']['Feature'].tolist()\n",
    "integer_features = [feat for feat in integer_features if feat != 'persoon_leeftijd_bij_onderzoek']\n",
    "\n",
    "# Scale integer features\n",
    "data_copy = scale_features(data_copy, integer_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "y = data_copy[['Ja', 'checked']]\n",
    "X = data_copy.drop(['Ja', 'Nee', 'checked'], axis=1).astype(np.float32)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Age Group Weights\n",
    "train_age_groups = pd.cut(\n",
    "    X_train['persoon_leeftijd_bij_onderzoek'],\n",
    "    bins=AGE_BINS,\n",
    "    labels=AGE_LABELS,\n",
    "    right=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and train the logistic regression model\n",
    "# Define the regularization strength (alpha)\n",
    "# This can be tuned using cross-validation\n",
    "ridge_alpha = 1.0  # Example value; you may want to optimize this\n",
    "\n",
    "# Create a Ridge regressor with the specified alpha\n",
    "regressor = Ridge(\n",
    "    alpha=ridge_alpha,\n",
    "    fit_intercept=True,\n",
    "    copy_X=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([('regression', regressor)])\n",
    "\n",
    "pipeline.fit(\n",
    "    X_train, y_train['Ja']\n",
    ")\n",
    "\n",
    "threshold = (0.697021996059818 + 0.697013377682873) / 2.0  #approx. boundary value in dataset\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test['checked'], y_pred > threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from onnx import helper\n",
    "import onnxruntime as rt\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = convert_sklearn(\n",
    "    pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "    target_opset=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add note to onnx graph such that it saves both the predicted risk value\n",
    "# and the 'checked' value based on if the risk value is higher than the\n",
    "# provided threshold.\n",
    "\n",
    "graph = onnx_model.graph\n",
    "threshold_node = helper.make_node(\n",
    "    \"Constant\",\n",
    "    inputs=[],\n",
    "    outputs=[\"threshold\"],\n",
    "    value=helper.make_tensor(\"value\", onnx.TensorProto.FLOAT, [], [threshold])\n",
    ")\n",
    "graph.node.append(threshold_node)\n",
    "\n",
    "greater_node = helper.make_node(\n",
    "    \"Greater\",\n",
    "    inputs=[graph.output[0].name, \"threshold\"],\n",
    "    outputs=[\"boolean_output\"]\n",
    ")\n",
    "graph.node.append(greater_node)\n",
    "\n",
    "boolean_output = helper.make_tensor_value_info(\"boolean_output\", onnx.TensorProto.BOOL, [None])\n",
    "graph.output.extend([boolean_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "# y_pred_onnx[0] = risk values\n",
    "# y_pred_onnx[1] = boolean value indicating if high risk or not\n",
    "accuracy_onnx_model = accuracy_score(y_test['checked'], y_pred_onnx[1])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(onnx_model, \"../model/model_1.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-Testing-33-9R5WRaXh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
